@inproceedings{kumar2018harnessing,
  title={Harnessing ai for speech reconstruction using multi-view silent video feed},
  author={Kumar, Yaman and Aggarwal, Mayank and Nawal, Pratham and Satoh, Shin'ichi and Shah, Rajiv Ratn and Zimmermann, Roger},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={1976--1983},
  year={2018}
}

@article{assael2016lipnet,
  title={Lipnet: End-to-end sentence-level lipreading},
  author={Assael, Yannis M and Shillingford, Brendan and Whiteson, Shimon and De Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01599},
  year={2016}
}

@inproceedings{martinez2020lipreading,
  title={Lipreading using temporal convolutional networks},
  author={Martinez, Brais and Ma, Pingchuan and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6319--6323},
  year={2020},
  organization={IEEE}
}

@article{zhu2022hformer,
  title={Hformer: Hybrid convolutional neural network transformer network for fringe order prediction in phase unwrapping of fringe projection},
  author={Zhu, Xinjun and Han, Zhiqiang and Yuan, Mengkai and Guo, Qinghua and Wang, Hongyi and Song, Limei},
  journal={Optical Engineering},
  volume={61},
  number={9},
  pages={093107--093107},
  year={2022},
  publisher={Society of Photo-Optical Instrumentation Engineers}
}

@inproceedings{meng2023merging,
  title={Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer},
  author={Meng, Mingyuan and Bi, Lei and Fulham, Michael and Feng, Dagan and Kim, Jinman},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={400--410},
  year={2023},
  organization={Springer}
}

@article{makhlouf2013hybrid,
  title={Hybrid Hidden Markov Models and genetic algorithm for Robust Automatic visual speech recognition},
  author={Makhlouf, Amina and Lazli, Lilia and Bensaker, Bachir},
  journal={Journal of Information Technology Review (JITR)},
  volume={4},
  number={3},
  pages={105--114},
  year={2013}
}

@inproceedings{pujari2021survey,
  title={A survey on deep learning based lip-reading techniques},
  author={Pujari, Sheetal and Sneha, SK and Vinusha, R and Bhuvaneshwari, P and Yashaswini, C},
  booktitle={2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)},
  pages={1286--1293},
  year={2021},
  organization={IEEE}
}

@inproceedings{kulkarni2019artificial,
  title={Artificial intelligence: a survey on lip-reading techniques},
  author={Kulkarni, Apurva H and Kirange, Dnyaneshwar},
  booktitle={2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@article{fernandez2018survey,
  title={Survey on automatic lip-reading in the era of deep learning},
  author={Fernandez-Lopez, Adriana and Sukno, Federico M},
  journal={Image and Vision Computing},
  volume={78},
  pages={53--72},
  year={2018},
  publisher={Elsevier}
}

@article{bear2017phoneme,
  title={Phoneme-to-viseme mappings: the good, the bad, and the ugly},
  author={Bear, Helen L and Harvey, Richard},
  journal={Speech Communication},
  volume={95},
  pages={40--67},
  year={2017},
  publisher={Elsevier}
}

@article{howell2016visual,
  title={Visual units and confusion modelling for automatic lip-reading},
  author={Howell, Dominic and Cox, Stephen and Theobald, Barry},
  journal={Image and Vision Computing},
  volume={51},
  pages={1--12},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{wang2024restoring,
  title={Restoring Speaking Lips from Occlusion for Audio-Visual Speech Recognition},
  author={Wang, Jiadong and Pan, Zexu and Zhang, Malu and Tan, Robby T and Li, Haizhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={19144--19152},
  year={2024}
}

@inproceedings{parekh2019lip,
  title={Lip reading using convolutional auto encoders as feature extractor},
  author={Parekh, Dharin and Gupta, Ankitesh and Chhatpar, Shharrnam and Yash, Anmol and Kulkarni, Manasi},
  booktitle={2019 IEEE 5th international conference for convergence in technology (I2CT)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{sarhan2021hlr,
  title={HLR-net: a hybrid lip-reading model based on deep convolutional neural networks},
  author={Sarhan, Amany M and Elshennawy, Nada M and Ibrahim, Dina M},
  journal={Computers, Materials and Continua},
  volume={68},
  number={2},
  pages={1531--49},
  year={2021},
  publisher={Tech Science Press}
}

@article{cooke2006audio,
  title={An audio-visual corpus for speech perception and automatic speech recognition},
  author={Cooke, Martin and Barker, Jon and Cunningham, Stuart and Shao, Xu},
  journal={The Journal of the Acoustical Society of America},
  volume={120},
  number={5},
  pages={2421--2424},
  year={2006},
  publisher={Acoustical Society of America}
}

@dataset{cooke_2006_3625687,
  author       = {Cooke, Martin and
                  Barker, Jon and
                  Cunningham, Stuart and
                  Shao, Xu},
  title        = {The Grid Audio-Visual Speech Corpus},
  month        = jan,
  year         = 2006,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.3625687},
  url          = {https://doi.org/10.5281/zenodo.3625687},
}

@article{selva2023video,
  title={Video transformers: A survey},
  author={Selva, Javier and Johansen, Anders S and Escalera, Sergio and Nasrollahi, Kamal and Moeslund, Thomas B and Clap{\'e}s, Albert},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={11},
  pages={12922--12943},
  year={2023},
  publisher={IEEE}
}

@article{lugaresi2019mediapipe,
  title={Mediapipe: A framework for building perception pipelines},
  author={Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming Guang and Lee, Juhyun and others},
  journal={arXiv preprint arXiv:1906.08172},
  year={2019}
}

@article{oghbaie2021advances,
  title={Advances and challenges in deep lip reading},
  author={Oghbaie, Marzieh and Sabaghi, Arian and Hashemifard, Kooshan and Akbari, Mohammad},
  journal={arXiv preprint arXiv:2110.07879},
  year={2021}
}

@article{wang2022lip,
  title={A lip reading method based on 3D convolutional vision transformer},
  author={Wang, Huijuan and Pu, Gangqiang and Chen, Tingyu},
  journal={IEEE Access},
  volume={10},
  pages={77205--77212},
  year={2022},
  publisher={IEEE}
}

@article{afouras2019my,
  title={My lips are concealed: Audio-visual speech enhancement through obstructions},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.04975},
  year={2019}
}

@inproceedings{anina2015ouluvs2,
  title={OuluVS2: A multi-view audiovisual database for non-rigid mouth motion analysis},
  author={Anina, Iuliia and Zhou, Ziheng and Zhao, Guoying and Pietik{\"a}inen, Matti},
  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
  volume={1},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@article{moons2018resource,
  title={Resource aware design of a deep convolutional-recurrent neural network for speech recognition through audio-visual sensor fusion},
  author={Moons, Bert and Verhelst, Marian and others},
  journal={arXiv preprint arXiv:1803.04840},
  year={2018}
}

@article{khan2023survey,
  title={A survey of the vision transformers and their CNN-transformer based variants},
  author={Khan, Asifullah and Rauf, Zunaira and Sohail, Anabia and Khan, Abdul Rehman and Asif, Hifsa and Asif, Aqsa and Farooq, Umair},
  journal={Artificial Intelligence Review},
  volume={56},
  number={Suppl 3},
  pages={2917--2970},
  year={2023},
  publisher={Springer}
}

@article{fisher1968confusions,
  title={Confusions among visually perceived consonants},
  author={Fisher, Cletus G},
  journal={Journal of speech and hearing research},
  volume={11},
  number={4},
  pages={796--804},
  year={1968},
  publisher={American Speech-Language-Hearing Association}
}

@article{mcgurk1976hearing,
  title={Hearing lips and seeing voices},
  author={McGurk, Harry and MacDonald, John},
  journal={Nature},
  volume={264},
  number={5588},
  pages={746--748},
  year={1976},
  publisher={Nature Publishing Group UK London}
}

@article{jeon2021lipreading,
  title={Lipreading architecture based on multiple convolutional neural networks for sentence-level visual speech recognition},
  author={Jeon, Sanghun and Elsharkawy, Ahmed and Kim, Mun Sang},
  journal={Sensors},
  volume={22},
  number={1},
  pages={72},
  year={2021},
  publisher={MDPI}
}

@inproceedings{chung2017lip,
  title={Lip reading in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ACCV 2016: 13th Asian Conference on Computer Vision, Taipei, Taiwan, November 20-24, 2016, Revised Selected Papers, Part II 13},
  pages={87--103},
  year={2017},
  organization={Springer}
}

@article{xiao20183d,
  title={3D feature pyramid attention module for robust visual speech recognition},
  author={Xiao, Jingyun},
  journal={arXiv preprint arXiv:1810.06178},
  year={2018}
}

@article{jeevakumari2024lipsyncnet,
  title={LipSyncNet: A Novel Deep Learning Approach for Visual Speech Recognition in Audio-Challenged Situations},
  author={Jeevakumari, SA Amutha and Dey, Koushik},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}

@inproceedings{xu2018lcanet,
  title={LCANet: End-to-end lipreading with cascaded attention-CTC},
  author={Xu, Kai and Li, Dawei and Cassimatis, Nick and Wang, Xiaolong},
  booktitle={2018 13th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2018)},
  pages={548--555},
  year={2018},
  organization={IEEE}
}

@article{haq2022using,
  title={Using lip reading recognition to predict daily Mandarin conversation},
  author={Haq, Muhamad Amirul and Ruan, Shanq-Jang and Cai, Wen-Jie and Li, Lieber Po-Hung},
  journal={IEEE Access},
  volume={10},
  pages={53481--53489},
  year={2022},
  publisher={IEEE}
}

@article{zhou2014review,
  title={A review of recent advances in visual speech decoding},
  author={Zhou, Ziheng and Zhao, Guoying and Hong, Xiaopeng and Pietik√§inen, Matti},
  journal={Image and Vision Computing},
  volume={32},
  number={9},
  pages={590--605},
  year={2014},
  publisher={Elsevier}
}

@article{matthews2002extraction,
  title={Extraction of visual features for lipreading},
  author={Matthews, Iain and Cootes, Timothy F and Bangham, J Andrew and Cox, Stephen and Harvey, Richard},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={24},
  number={2},
  pages={198--213},
  year={2002},
  publisher={IEEE}
}

@article{neti2000audio,
  title={Audio visual speech recognition},
  author={Neti, Chalapathy and Potamianos, Gerasimos and Luettin, Juergen and Matthews, Iain and Glotin, Herve and Vergyri, Dimitra and Sison, June and Mashari, Azad},
  year={2000},
  publisher={IDIAP}
}

@incollection{goldschen1997continuous,
  title={Continuous automatic speech recognition by lipreading},
  author={Goldschen, Alan J and Garcia, Oscar N and Petajan, Eric D},
  booktitle={Motion-Based recognition},
  pages={321--343},
  year={1997},
  publisher={Springer}
}

@article{potamianos2003recent,
  title={Recent advances in the automatic recognition of audiovisual speech},
  author={Potamianos, Gerasimos and Neti, Chalapathy and Gravier, Guillaume and Garg, Ashutosh and Senior, Andrew W},
  journal={Proceedings of the IEEE},
  volume={91},
  number={9},
  pages={1306--1326},
  year={2003},
  publisher={IEEE}
}

@inproceedings{lucey2007patch,
  title={Patch-based representation of visual speech},
  author={Lucey, Patrick and Sridharan, Subramanian},
  booktitle={Proceedings of the HCSNet Workshop on the Use of Vision in Human-Computer Interaction},
  pages={79--85},
  year={2007},
  organization={Australian Computer Society}
}

@inproceedings{gergen2016dynamic,
  title={Dynamic Stream Weighting for Turbo-Decoding-Based Audiovisual ASR.},
  author={Gergen, Sebastian and Zeiler, Steffen and Abdelaziz, Ahmed Hussen and Nickel, Robert M and Kolossa, Dorothea},
  booktitle={INTERSPEECH},
  pages={2135--2139},
  year={2016}
}

@article{park5055344swinlip,
  author = {Park, Young-Hu and Park, Rae-Hong and Park, Hyung-Min},
  year = {2024},
  month = {01},
  pages = {},
  title = {Swinlip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer},
  doi = {10.2139/ssrn.5055344}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{gutierrez2017lip,
  title={Lip reading word classification},
  author={Gutierrez, Abiel and Robert, Z},
  journal={Comput Vision-ACCV},
  pages={1--9},
  year={2017}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{fung2018end,
  title={End-to-end low-resource lip-reading with maxout CNN and LSTM},
  author={Fung, Ivan and Mak, Brian},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2511--2515},
  year={2018},
  organization={IEEE}
}

@article{garg2016lip,
  title={Lip reading using CNN and LSTM},
  author={Garg, Amit and Noyola, Jonathan and Bagadia, Sameep},
  journal={Technical report, Stanford University, CS231 n project report},
  year={2016}
}

@inproceedings{devi2023silent,
  title={Silent Speech Recognition: Automatic Lip Reading Model Using 3D CNN and GRU},
  author={Devi, T Mallika and Keerthana, Siripurapu and Santhi, Pentyala and Pravallika, Puram and Rajeshwari, Sama},
  booktitle={International Conference on Data Science, Machine Learning and Applications},
  pages={827--832},
  year={2023},
  organization={Springer}
}

@article{xue2023fine,
  title={Fine-grained sequence-to-sequence lip reading based on self-attention and self-distillation},
  author={Xue, Junxiao and Huang, Shibo and Song, Huawei and Shi, Lei},
  journal={Frontiers of Computer Science},
  volume={17},
  number={6},
  pages={176344},
  year={2023},
  publisher={Springer}
}

@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={22--31},
  year={2021}
}

@article{shirakata2020lip,
  title={Lip reading using facial expression features},
  author={Shirakata, Tasuya and Saitoh, Takeshi},
  journal={Int. J. Comput. Vis. Signal Process},
  volume={1},
  number={1},
  pages={9--15},
  year={2020}
}

@inproceedings{rekik2014new,
  title={A new visual speech recognition approach for RGB-D cameras},
  author={Rekik, Ahmed and Ben-Hamadou, Achraf and Mahdi, Walid},
  booktitle={Image Analysis and Recognition: 11th International Conference, ICIAR 2014, Vilamoura, Portugal, October 22-24, 2014, Proceedings, Part II 11},
  pages={21--28},
  year={2014},
  organization={Springer}
}

@inproceedings{patterson2002cuave,
  title={CUAVE: A new audio-visual database for multimodal human-computer interface research},
  author={Patterson, Eric K and Gurbuz, Sabri and Tufekci, Zekeriya and Gowdy, John N},
  booktitle={2002 IEEE International conference on acoustics, speech, and signal processing},
  volume={2},
  pages={II--2017},
  year={2002},
  organization={IEEE}
}

@inproceedings{son2017lip,
  title={Lip reading sentences in the wild},
  author={Son Chung, Joon and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6447--6456},
  year={2017}
}

@article{afouras2018deep,
  title={Deep audio-visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={12},
  pages={8717--8727},
  year={2018},
  publisher={IEEE}
}

@article{afouras2018lrs3,
  title={LRS3-TED: a large-scale dataset for visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1809.00496},
  year={2018}
}

@inproceedings{son2017lipprofile,
  title={Lip reading in profile},
  author={Son, Joon Son and Zisserman, Andrew},
  booktitle={Proceedings of the British Machine Vision Conference},
  volume={2017},
  year={2017}
}

@inproceedings{yang2019lrw,
  title={LRW-1000: A naturally-distributed large-scale benchmark for lip reading in the wild},
  author={Yang, Shuang and Zhang, Yuanhang and Feng, Dalu and Yang, Mingmin and Wang, Chenhao and Xiao, Jingyun and Long, Keyu and Shan, Shiguang and Chen, Xilin},
  booktitle={2019 14th IEEE international conference on automatic face \& gesture recognition (FG 2019)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{kastaniotis2019lip,
  title={Lip Reading in Greek words at unconstrained driving scenario},
  author={Kastaniotis, Dimitris and Tsourounis, Dimitrios and Koureleas, Aristotelis and Peev, Bojidar and Theoharatos, Christos and Fotopoulos, Spiros},
  booktitle={2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{jitaru2020lrro,
  title={Lrro: a lip reading data set for the under-resourced romanian language},
  author={Jitaru, Andrei Cosmin and Abdulamit, {\c{S}}eila and Ionescu, Bogdan},
  booktitle={Proceedings of the 11th ACM Multimedia Systems Conference},
  pages={267--272},
  year={2020}
}

@inproceedings{kumar2020harnessing,
  title={Harnessing gans for zero-shot learning of new classes in visual speech recognition},
  author={Kumar, Yaman and Sahrawat, Dhruva and Maheshwari, Shubham and Mahata, Debanjan and Stent, Amanda and Yin, Yifang and Shah, Rajiv Ratn and Zimmermann, Roger},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={2645--2652},
  year={2020}
}

@article{katsamanis2009face,
  title={Face active appearance modeling and speech acoustic information to recover articulation},
  author={Katsamanis, Athanassios and Papandreou, George and Maragos, Petros},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={17},
  number={3},
  pages={411--422},
  year={2009},
  publisher={IEEE}
}

@inproceedings{luettin1996visual,
  title={Visual speech recognition using active shape models and hidden Markov models},
  author={Luettin, Juergen and Thacker, Neil A and Beet, Steve W},
  booktitle={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  volume={2},
  pages={817--820},
  year={1996},
  organization={IEEE}
}

@article{cho2014properties,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@article{oghbaie2025deep,
  title={When deep learning deciphers silent video: a survey on automatic deep lip reading},
  author={Oghbaie, Marzieh and Sabaghi, Arian and Hashemifard, Kooshan and Akbari, Mohammad},
  journal={Multimedia Tools and Applications},
  pages={1--43},
  year={2025},
  publisher={Springer}
}

@inproceedings{nadeemhashmi2018lip,
  title={A lip reading model using CNN with batch normalization},
  author={NadeemHashmi, Saquib and Gupta, Harsh and Mittal, Dhruv and Kumar, Kaushtubh and Nanda, Aparajita and Gupta, Sarishty},
  booktitle={2018 eleventh international conference on contemporary computing (IC3)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{fu2023chinese,
  title={Chinese lip-reading research based on ShuffleNet and CBAM},
  author={Fu, Yixian and Lu, Yuanyao and Ni, Ran},
  journal={Applied Sciences},
  volume={13},
  number={2},
  pages={1106},
  year={2023},
  publisher={MDPI}
}

@article{arakane2023efficient,
  title={Efficient DNN model for word lip-reading},
  author={Arakane, Taiki and Saitoh, Takeshi},
  journal={Algorithms},
  volume={16},
  number={6},
  pages={269},
  year={2023},
  publisher={MDPI}
}

@inproceedings{guo2019depthwise,
  title={Depthwise convolution is all you need for learning multiple visual domains},
  author={Guo, Yunhui and Li, Yandong and Wang, Liqiang and Rosing, Tajana},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={8368--8375},
  year={2019}
}

@article{ahn2023linear,
  title={Linear attention is (maybe) all you need (to understand transformer optimization)},
  author={Ahn, Kwangjun and Cheng, Xiang and Song, Minhak and Yun, Chulhee and Jadbabaie, Ali and Sra, Suvrit},
  journal={arXiv preprint arXiv:2310.01082},
  year={2023}
}

@inproceedings{phan2022patch,
  title={Patch embedding as local features: Unifying deep local and global features via vision transformer for image retrieval},
  author={Phan, Lam and Nguyen, Hiep Thi Hong and Warrier, Harikrishna and Gupta, Yogesh},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={2527--2544},
  year={2022}
}

@article{lee2023mathematical,
  title={Mathematical analysis and performance evaluation of the gelu activation function in deep learning},
  author={Lee, Minhyeok},
  journal={Journal of Mathematics},
  volume={2023},
  number={1},
  pages={4229924},
  year={2023},
  publisher={Wiley Online Library}
}

@inproceedings{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={357--366},
  year={2021}
}

@article{yin2024novel,
  title={A novel fish individual recognition method for precision farming based on knowledge distillation strategy and the range of the receptive field},
  author={Yin, Jianhao and Wu, Junfeng and Gao, Chunqi and Yu, Hong and Liu, Liang and Guo, Shihao},
  journal={Journal of Fish Biology},
  volume={105},
  number={3},
  pages={721--734},
  year={2024},
  publisher={Wiley Online Library}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@InProceedings{Hu_2018_CVPR,
  author = {Hu, Jie and Shen, Li and Sun, Gang},
  title = {Squeeze-and-Excitation Networks},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2018}
}

@article{liu2024mspe,
  title={MSPE: Multi-Scale Patch Embedding Prompts Vision Transformers to Any Resolution},
  author={Liu, Wenzhuo and Zhu, Fei and Ma, Shijie and Liu, Cheng-Lin},
  journal={arXiv preprint arXiv:2405.18240},
  year={2024}
}

@inproceedings{wu2023transformerlight,
  title={Transformerlight: A novel sequence modeling based traffic signaling mechanism via gated transformer},
  author={Wu, Qiang and Li, Mingyuan and Shen, Jun and L{\"u}, Linyuan and Du, Bo and Zhang, Ke},
  booktitle={Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining},
  pages={2639--2647},
  year={2023}
}

@incollection{graves2012connectionist,
  title={Connectionist temporal classification},
  author={Graves, Alex},
  booktitle={Supervised sequence labelling with recurrent neural networks},
  pages={61--93},
  year={2012},
  publisher={Springer}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{bird2006nltk,
  title={NLTK: the natural language toolkit},
  author={Bird, Steven},
  booktitle={Proceedings of the COLING/ACL 2006 interactive presentation sessions},
  pages={69--72},
  year={2006}
}

@inproceedings{hong2023watch,
  title={Watch or listen: Robust audio-visual speech recognition with visual corruption modeling and reliability scoring},
  author={Hong, Joanna and Kim, Minsu and Choi, Jeongsoo and Ro, Yong Man},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18783--18794},
  year={2023}
}

@inproceedings{bulzomi2023end,
  title={End-to-end neuromorphic lip-reading},
  author={Bulzomi, Hugo and Schweiker, Marcel and Gruel, Am{\'e}lie and Martinet, Jean},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4101--4108},
  year={2023}
}

@inproceedings{wang2024mlca,
  title={Mlca-avsr: Multi-layer cross attention fusion based audio-visual speech recognition},
  author={Wang, He and Guo, Pengcheng and Zhou, Pan and Xie, Lei},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8150--8154},
  year={2024},
  organization={IEEE}
}

@article{springenberg2014striving,
  title={Striving for simplicity: The all convolutional net},
  author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1412.6806},
  year={2014}
}
